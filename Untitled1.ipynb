{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from scipy.spatial import distance as dist\n",
    "import collections\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier('classificadores/haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_extractor(img):\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.2, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "contagem = 0\n",
    "\n",
    "# IMPLEMENTAR\n",
    "# Defina o número máximo de imagens a serem coletadas\n",
    "\n",
    "contagem_maxima = 500\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        cv2.imshow(\"Imagem de Treino\", frame)\n",
    "        \n",
    "        # IMPLEMENTAR\n",
    "        # Crie um algoritmo para salvar as imagens segmentadas em face em um determinado diretório\n",
    "        face = face_extractor(frame)\n",
    "        if face is not None:\n",
    "            file = \"faces_p_treinamento/\"+str(contagem)+\".png\"\n",
    "            gray = cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n",
    "            cv2.imwrite(file, gray)  \n",
    "            contagem += 1\n",
    "        \n",
    "        # Se for teclado Enter (tecla 13) deverá sair do loop e encerrar a captura de imagem\n",
    "        # ou for alcançado a contagem máxima (amostras)\n",
    "        if cv2.waitKey(1) == 13 or contagem == contagem_maxima:\n",
    "            break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Coleta de amostras completado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPLEMENTAR\n",
    "# Defina o diretório utilizado para salvar as faces de exemplo\n",
    "\n",
    "data_path = \"faces_p_treinamento/\"\n",
    "\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "training_data, labels = [], []\n",
    "\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    training_data.append(images)\n",
    "    labels.append(0)\n",
    "\n",
    "# Criando uma matriz da lista de labels\n",
    "labels = np.asarray(labels, dtype=np.int32)\n",
    "\n",
    "# Treinamento do modelo\n",
    "model = cv2.face.LBPHFaceRecognizer_create()\n",
    "model.train(training_data, labels)\n",
    "\n",
    "print(\"Modelo treinado com sucesso.\")\n",
    "\n",
    "# IMPLEMENTAR\n",
    "# Defina na chave 0 o nome do candidato\n",
    "\n",
    "persons = {0: \"evandro\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret:\n",
    "        \n",
    "        # IMPLEMENTAR\n",
    "        # Extraia a face da imagem obtida da câmera\n",
    "        # Faça os ajustes necessários para classificá-la no classifcador treinado\n",
    "        # Estabeleça um algoritmo para concluir se o resultado é 'Sucesso', candidato identificado ou 'Não Indetificado' para\n",
    "        # quando não for localizado o candidato\n",
    "        # Analise também situações onde a face não é identificada\n",
    "        # Utilize a função face_extractor para segmentar a imagem de rosto\n",
    "\n",
    "        face = face_extractor(frame)\n",
    "        \n",
    "        if face is not None:\n",
    "            gray = cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n",
    "            id, confidence = model.predict(gray)\n",
    "\n",
    "            if (confidence < 40 ):\n",
    "                id = persons[id]\n",
    "                cv2.putText(frame,\"Sucesso!!, achei o \" + str(id),(100,100),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0),2)\n",
    "                ## salva evidencia\n",
    "                cv2.imwrite(\"imagens/person_identificado.png\", frame) \n",
    "            else:\n",
    "                cv2.putText(frame,\"Não Indetificado\",(100,100),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2)\n",
    "\n",
    "        cv2.imshow(\"Identificacao de Faces\", frame)\n",
    "\n",
    "        # Se for teclado Enter (tecla 13) deverá sair do loop e encerrar a captura de imagem    \n",
    "        if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "            break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"imagens/person_identificado.png\", frame) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
