{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from scipy.spatial import distance as dist\n",
    "import collections\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier('classificadores/haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_extractor(img):\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.2, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coleta de amostras completado\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "contagem = 0\n",
    "\n",
    "# IMPLEMENTAR\n",
    "# Defina o número máximo de imagens a serem coletadas\n",
    "\n",
    "contagem_maxima = 30\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        cv2.imshow(\"Imagem de Treino\", frame)\n",
    "        \n",
    "        # IMPLEMENTAR\n",
    "        # Crie um algoritmo para salvar as imagens segmentadas em face em um determinado diretório\n",
    "        face = face_extractor(frame)\n",
    "        file = \"faces_p_treinamento/\"+str(contagem)+\".png\"\n",
    "        cv2.imwrite(file, face)  \n",
    "        contagem += 1\n",
    "        \n",
    "        # Se for teclado Enter (tecla 13) deverá sair do loop e encerrar a captura de imagem\n",
    "        # ou for alcançado a contagem máxima (amostras)\n",
    "        if cv2.waitKey(1) == 13 or contagem == contagem_maxima:\n",
    "            break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Coleta de amostras completado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo treinado com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# IMPLEMENTAR\n",
    "# Defina o diretório utilizado para salvar as faces de exemplo\n",
    "\n",
    "data_path = \"faces_p_treinamento/\"\n",
    "\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "training_data, labels = [], []\n",
    "\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    training_data.append(images)\n",
    "    labels.append(0)\n",
    "\n",
    "# Criando uma matriz da lista de labels\n",
    "labels = np.asarray(labels, dtype=np.int32)\n",
    "\n",
    "# Treinamento do modelo\n",
    "model = cv2.face.LBPHFaceRecognizer_create()\n",
    "model.train(training_data, labels)\n",
    "\n",
    "print(\"Modelo treinado com sucesso.\")\n",
    "\n",
    "# IMPLEMENTAR\n",
    "# Defina na chave 0 o nome do candidato\n",
    "\n",
    "persons = {0: \"evandro\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-f1aa7dda34b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;31m#gray = cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m                 \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfidence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret:\n",
    "        \n",
    "        # IMPLEMENTAR\n",
    "        # Extraia a face da imagem obtida da câmera\n",
    "        # Faça os ajustes necessários para classificá-la no classifcador treinado\n",
    "        # Estabeleça um algoritmo para concluir se o resultado é 'Sucesso', candidato identificado ou 'Não Indetificado' para\n",
    "        # quando não for localizado o candidato\n",
    "        # Analise também situações onde a face não é identificada\n",
    "        # Utilize a função face_extractor para segmentar a imagem de rosto\n",
    "    \n",
    "        face = face_extractor(frame)\n",
    "\n",
    "\n",
    "            for (x,y,w,h) in frame:\n",
    "                cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "                id, confidence = model.predict(face)\n",
    "\n",
    "            if (confidence < 100 ):\n",
    "                id = persons[id]\n",
    "                confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "            else:\n",
    "                id = \"Pessoa estranha!\"\n",
    "                confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "\n",
    "            cv2.putText(frame,str(id),(x+5,y-5),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2)\n",
    "            cv2.putText(frame,str(confidence),(x+5,y+h-5),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,0),1) \n",
    "\n",
    "        cv2.imshow(\"Identificacao de Faces\", frame)\n",
    "\n",
    "        # Se for teclado Enter (tecla 13) deverá sair do loop e encerrar a captura de imagem    \n",
    "        if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "            break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
