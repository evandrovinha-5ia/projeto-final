{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPLEMENTAR\n",
    "# Para cada constante abaixo, indique uma lista de pontos dos 68 identificados pelo classificador do DLib\n",
    "FACE_POINTS = list(range(17, 68))\n",
    "MOUTH_POINTS = list(range(48, 61))\n",
    "RIGHT_BROW_POINTS = list(range(17, 22))\n",
    "LEFT_BROW_POINTS = list(range(22, 27))\n",
    "RIGHT_EYE_POINTS = list(range(36, 42))\n",
    "LEFT_EYE_POINTS = list(range(42, 48))\n",
    "NOSE_POINTS = list(range(27, 35))\n",
    "JAW_POINTS = list(range(0, 17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mouth_aspect_ratio(mouth):\n",
    "    \n",
    "    # IMPLEMENTAR\n",
    "    # Utilize referências do paper para calcular o MAR (Mouth Aspect Ratio)\n",
    "    \n",
    "    from scipy.spatial import distance as dist\n",
    "    \n",
    "    A = dist.euclidean(mouth[3], mouth[9])\n",
    "    B = dist.euclidean(mouth[2], mouth[10])\n",
    "    C = dist.euclidean(mouth[4], mouth[8])\n",
    "    avg = (A+B+C)/3\n",
    "    D = dist.euclidean(mouth[0], mouth[6])\n",
    "    mar=avg/D\n",
    "\n",
    "    \n",
    "    return mar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import numpy \n",
    "\n",
    "predictor_68_path = \"modelos/shape_predictor_68_face_landmarks.dat\"\n",
    "\n",
    "predictor = dlib.shape_predictor(predictor_68_path)\n",
    "detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_landmarks_convex_hull_image(im):\n",
    "    im = im.copy()\n",
    "    rects = detector(im, 1)\n",
    "    \n",
    "    if len(rects) == 0:\n",
    "        return im, 0, 0\n",
    "    \n",
    "    landmarks_list = []\n",
    "    \n",
    "    for rect in rects:\n",
    "        landmarks = numpy.matrix([[p.x, p.y] for p in predictor(im, rect).parts()])\n",
    "\n",
    "        for k, d in enumerate(rects):\n",
    "            cv2.rectangle(im, (d.left(), d.top()), (d.right(), d.bottom()), (0, 255, 0), 2)\n",
    "\n",
    "            points = cv2.convexHull(landmarks[NOSE_POINTS])\n",
    "            cv2.drawContours(im, [points], 0, (0, 255, 0), 1)\n",
    "\n",
    "            points = cv2.convexHull(landmarks[MOUTH_POINTS])\n",
    "            cv2.drawContours(im, [points], 0, (0, 255, 0), 1)\n",
    "            \n",
    "            points = cv2.convexHull(landmarks[RIGHT_BROW_POINTS])\n",
    "            cv2.drawContours(im, [points], 0, (0, 255, 0), 1)\n",
    "\n",
    "            points = cv2.convexHull(landmarks[LEFT_BROW_POINTS])\n",
    "            cv2.drawContours(im, [points], 0, (0, 255, 0), 1)\n",
    "\n",
    "            points = cv2.convexHull(landmarks[RIGHT_EYE_POINTS])\n",
    "            cv2.drawContours(im, [points], 0, (0, 255, 0), 1)\n",
    "            \n",
    "            points = cv2.convexHull(landmarks[LEFT_EYE_POINTS])\n",
    "            cv2.drawContours(im, [points], 0, (0, 255, 0), 1)\n",
    "            \n",
    "            mouth_aspect = mouth_aspect_ratio(landmarks[MOUTH_POINTS])\n",
    "            eye_aspect = None\n",
    "\n",
    "    return im, mouth_aspect, eye_aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorriso_minimo = 0.40\n",
    "sorrimo_maximo = 0.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a39d9ffc510b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#cam_capture.release()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcam_capture\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Quantidade de sorrisos identificados\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "#cam_capture.release()\n",
    "cam_capture = cv2.VideoCapture(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Quantidade de sorrisos identificados\n",
    "qtde_sorrisos = 0\n",
    "prev_sorriso = True #iniciamos com a possibilidade de haver um sorriso\n",
    "\n",
    "while True:\n",
    "    ret, image_frame = cam_capture.read()\n",
    "\n",
    "    if ret:\n",
    "        image_frame, mouth_aspect, _ = annotate_landmarks_convex_hull_image(image_frame)\n",
    "        \n",
    "        # IMPLEMENTAR\n",
    "        # Defina o algoritmo que irá identificar o sorriso baseado nos limites defindos\n",
    "        # Crie uma lógica para contar quantas vezes o sorriso foi dado\n",
    "        \n",
    "        cv2.putText(image_frame,\"MAR: \" + str(mouth_aspect),(100,100),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,255),2)\n",
    "       \n",
    "        if mouth_aspect >= sorriso_minimo and mouth_aspect <= sorrimo_maximo and prev_sorriso and count_frames < 15:\n",
    "            qtde_sorrisos += 1\n",
    "            prev_sorriso = False #para não registra o mesmo sorriso mais de 1x\n",
    "            cv2.imwrite(\"imagens/person_sorrindo.png\", frame)  # registra evedencia do sorriso.\n",
    "\n",
    "        if mouth_aspect < sorriso_minimo and prev_sorriso == False: #Antes estava sorrindo e fechou a boca\n",
    "            prev_sorriso = True\n",
    "           \n",
    "        cv2.putText(image_frame,\"Sorrisos: \" + str(qtde_sorrisos),(100,125),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2)\n",
    "        \n",
    "        cv2.imshow(\"Detector de Sorriso\", image_frame)\n",
    "        \n",
    "        # Se for teclado Enter (tecla 13) deverá sair do loop e encerrar a captura de imagem   \n",
    "        if cv2.waitKey(1) == 13:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cam_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Import required modules\n",
    "import cv2\n",
    "import dlib\n",
    "\n",
    "#Dlib positions\n",
    "#  (\"mouth\", (48, 68)),\n",
    "#\t(\"right_eyebrow\", (17, 22)),\n",
    "#\t(\"left_eyebrow\", (22, 27)),\n",
    "#\t(\"right_eye\", (36, 42)),\n",
    "#\t(\"left_eye\", (42, 48)),\n",
    "#\t(\"nose\", (27, 35)),\n",
    "#\t(\"jaw\", (0, 17))\n",
    "\n",
    "#Set up some required objects\n",
    "video_capture = cv2.VideoCapture(0) #Webcam object\n",
    "#Change Frame Rate\n",
    "\n",
    "detector = dlib.get_frontal_face_detector() #Face detector\n",
    "#Landmark identifier. Set the filename to whatever you named the downloaded file\n",
    "predictor = dlib.shape_predictor(\"modelos/shape_predictor_68_face_landmarks.dat\") \n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "    frame = cv2.flip(frame,180) \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    clahe_image = clahe.apply(gray)\n",
    "\n",
    "    detections = detector(clahe_image, 1) #Detect the faces in the image\n",
    "\n",
    "    for k,d in enumerate(detections): #For each detected face  \n",
    "        shape = predictor(clahe_image, d) #Get coordinates\n",
    "        for i in range(1,68): #There are 68 landmark points on each face\n",
    "            cv2.circle(frame, (shape.part(i).x, shape.part(i).y), 1, (0,255,0), thickness=-1) #For each point, draw a red circle with thickness2 on the original frame\n",
    "            #cv2.putText(frame, str(i), (shape.part(i).x,shape.part(i).y),\n",
    "            #        fontFace=cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,\n",
    "            #        fontScale=0.3,\n",
    "            #        color=(0, 0, 255))\n",
    "    cv2.imshow(\"image\", frame) #Display the frame\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): #Exit program when the user presses 'q'\n",
    "        break\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
